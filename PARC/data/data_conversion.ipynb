{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f856b3-ebd3-4302-a22f-3b7cc6775aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage.measure import block_reduce\n",
    "from IPython.display import clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d7f8b3-b262-4a00-b8a0-473073739228",
   "metadata": {},
   "source": [
    "# Optional\n",
    "## Check a data file and ensure columns match the requirement ['X', 'Y', 'U','V', 'P', 'T']\n",
    "### Drop any additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78b033-9e8d-444e-b00a-c5da107e3de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/scratch/jtb3sud/TNT/183102/TNT_1.730000MICRON_1.000000Gpa/xyuvpTLs_ts0006000.dat\"\n",
    "#path = \"/home/pdy2bw/Research/PARCv2/Void_Collapse.interp.ts0003000.dat\"\n",
    "\n",
    "os.path.exists(path)\n",
    "\n",
    "read_data = np.genfromtxt(path, \n",
    "                        invalid_raise=False, \n",
    "                        missing_values=None)\n",
    "clear_output(wait=True)\n",
    "\n",
    "df = pd.DataFrame(read_data, columns =['X', 'Y', 'U','V', 'P', 'T', 'Ls']) \n",
    "df = df.drop(['Ls'], axis=1)\n",
    "df.head(5)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf85b3-4b08-462d-9542-c57ee9716fc1",
   "metadata": {},
   "source": [
    "# Required\n",
    "## Once file is in correct format, run data conversion: raw -> numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294cf56-9cdf-4b7b-84af-3e2567fcd67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_file(filepath):\n",
    "    \"\"\"\n",
    "    Process a single file.\n",
    "    \"\"\"\n",
    "    # Read data from file\n",
    "    read_data = np.genfromtxt(filepath, invalid_raise=False, missing_values=None)\n",
    "    #print(read_data)\n",
    "    \n",
    "    df = pd.DataFrame(read_data, columns=['X', 'Y', 'U', 'V', 'P', 'T', 'Ls'])\n",
    "    df = df.drop(['Ls'], axis=1)\n",
    "    #print(\"----------------------------------------------\",df)\n",
    "    # Process temperature field\n",
    "    temperature_snapshot_raw = df.pivot_table(index='X', columns='Y', values='T').T.values\n",
    "    #print(\"raw\", temperature_snapshot_raw)\n",
    "    temperature_snapshot = pd.DataFrame(temperature_snapshot_raw).round(6).to_numpy()\n",
    "    temperature_snapshot = np.expand_dims(temperature_snapshot, axis=2)\n",
    "    #print(\"temperature\", temperature_snapshot)\n",
    "\n",
    "    # Process pressure field\n",
    "    pressure_snapshot_raw = df.pivot_table(index='X', columns='Y', values='P').T.values\n",
    "    pressure_snapshot = pd.DataFrame(pressure_snapshot_raw).round(6).to_numpy()\n",
    "    pressure_snapshot = np.expand_dims(pressure_snapshot, axis=2)\n",
    "\n",
    "    # Process microstructure field\n",
    "    microstructure_snapshot = temperature_snapshot\n",
    "\n",
    "    # Process velocity_x field\n",
    "    vx_snapshot_raw = df.pivot_table(index='X', columns='Y', values='U').T.values\n",
    "    vx_snapshot = pd.DataFrame(vx_snapshot_raw).round(6).to_numpy()\n",
    "    vx_snapshot = np.expand_dims(vx_snapshot, axis=2)\n",
    "\n",
    "    # Process velocity_y field\n",
    "    vy_snapshot_raw = df.pivot_table(index='X', columns='Y', values='V').T.values\n",
    "    vy_snapshot = pd.DataFrame(vy_snapshot_raw).round(6).to_numpy()\n",
    "    vy_snapshot = np.expand_dims(vy_snapshot, axis=2)\n",
    "\n",
    "    # Combine all snapshots\n",
    "    coupled_field_snapshot = np.concatenate([temperature_snapshot,\n",
    "                                              pressure_snapshot,\n",
    "                                              microstructure_snapshot,\n",
    "                                              vx_snapshot,\n",
    "                                              vy_snapshot], axis=2)\n",
    "    # Cut off temperature to have value from 300 - max temp\n",
    "    # how do we choose these numbers\n",
    "    coupled_field_snapshot[:,:,0][coupled_field_snapshot[:,:,0] < 300] = 300\n",
    "    coupled_field_snapshot[:,:,0][coupled_field_snapshot[:,:,0] > 5000] = 7000\n",
    "    \n",
    "    # Convert microstructure field to binary image\n",
    "    coupled_field_snapshot[:,:,2][coupled_field_snapshot[:,:,2] > 280] = 280\n",
    "    coupled_field_snapshot[:,:,2][coupled_field_snapshot[:,:,2] < 280] = 0\n",
    "#    \n",
    "    return coupled_field_snapshot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_subdirectory(subdirectory, np_directory):\n",
    "    \"\"\"\n",
    "    Process all files in a subdirectory.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Loop through each subdirectory in the subdirectory\n",
    "    for inner_subdirectory in os.listdir(subdirectory):\n",
    "        inner_subdirectory_path = os.path.join(subdirectory, inner_subdirectory)\n",
    "        #print(\"inner_subdirectory\", inner_subdirectory_path)\n",
    "        \n",
    "        # Check if the path is a directory\n",
    "        if os.path.isdir(inner_subdirectory_path):\n",
    "            # List all files in the inner subdirectory\n",
    "            files = os.listdir(inner_subdirectory_path)\n",
    "\n",
    "            # Extract ts from each file name and sort files based on ts\n",
    "            files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0][2:]))\n",
    "            # hold the data\n",
    "            coupled_field_evolution = []\n",
    "            # Loop through each file in the inner subdirectory\n",
    "            for filename in files:\n",
    "                filepath = os.path.join(inner_subdirectory_path, filename)\n",
    "                #print(\"filepath\", filepath)\n",
    "\n",
    "                # Check if the path is a file\n",
    "                if os.path.isfile(filepath):\n",
    "                    # Process the file and append the snapshot to the list\n",
    "                    snapshot = process_file(filepath)\n",
    "                    #print(snapshot)\n",
    "                    coupled_field_evolution.append(snapshot)\n",
    "            coupled_field_evolution = np.concatenate(coupled_field_evolution, axis = 2)\n",
    "            last_part = subdirectory[subdirectory.rfind('/') + 1:]\n",
    "            np.save(os.path.join(np_directory, f'{last_part}.npy'), coupled_field_evolution)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_directory(root_directory, np_directory):\n",
    "    \"\"\"\n",
    "    Process all subdirectories in the root directory.\n",
    "    \"\"\"\n",
    "    #data_snapshots = []\n",
    "\n",
    "    # Loop through each subdirectory in the root directory\n",
    "    i = 0\n",
    "    for subdirectory in os.listdir(root_directory):\n",
    "        i += 1\n",
    "        subdirectory_path = os.path.join(root_directory, subdirectory)\n",
    "        #print(\"subdirectory\", subdirectory_path)\n",
    "        \n",
    "        # Check if the path is a directory\n",
    "        if os.path.isdir(subdirectory_path):\n",
    "            # Process the subdirectory and append the snapshots to the list\n",
    "            process_subdirectory(subdirectory_path, np_directory)\n",
    "            #data_snapshots.extend(snapshots)\n",
    "            \n",
    "        print(\"File number\", i, \"complete\")\n",
    "            \n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to start the process.\n",
    "    \"\"\"\n",
    "    # Define the root directory to start processing\n",
    "    root_directory = '/scratch/jtb3sud/TNT/'\n",
    "    np_directory = '/scratch/jtb3sud/tnt_np/'\n",
    "\n",
    "    # Process the root directory\n",
    "    process_directory(root_directory, np_directory)\n",
    "    \n",
    "    return \n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()\n",
    "\n",
    "hold = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa03c7-f7f6-4855-a0fd-2fc54c946167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/sfs/qumulo/qhome/jtb3sud/PARCv2\")\n",
    "from PARC.utils import convert_data_to_numpy\n",
    "\"\"\"\n",
    "Convert raw data to numpy arrays.\n",
    "\"\"\"\n",
    "# Define the root directory to start processing\n",
    "root_directory = '/scratch/jtb3sud/TNT/'\n",
    "np_directory = '/scratch/jtb3sud/tnt_np/'\n",
    "\n",
    "convert_data_to_numpy(root_directory, np_directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf3133-50b6-429a-b3f2-8c819fa4e19d",
   "metadata": {},
   "source": [
    "# Split into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626c313-8653-496a-b39a-2ebe54d13ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/sfs/qumulo/qhome/jtb3sud/PARCv2\")\n",
    "from PARC.utils import split_data_into_train_test\n",
    "\n",
    "# Set the paths\n",
    "folder_path = '/scratch/jtb3sud/tnt_np'\n",
    "training_path = '/scratch/jtb3sud/meta_data/tnt/training'\n",
    "testing_path = '/scratch/jtb3sud/meta_data/tnt/testing'\n",
    "\n",
    "# Call the function to split data into training and testing directories\n",
    "split_data_into_train_test(folder_path, training_path, testing_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33c7c2-cab1-417b-b8a4-4c64c6ae1069",
   "metadata": {},
   "source": [
    "# Visualize the data to ensure it was converted properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29029187-f129-481a-ac2c-01812cf9c1d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/sfs/qumulo/qhome/jtb3sud/PARCv2\")\n",
    "from PARC.utils import create_gif_from_numpy_array\n",
    "\n",
    "create_gif_from_numpy_array('/scratch/jtb3sud/meta_data/tnt/training/183119.npy', '/sfs/qumulo/qhome/jtb3sud/PARCv2/PARC/data/gifs/5733390_animation.gif')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7243d-4af9-45fd-a598-a4a6ac51f71b",
   "metadata": {},
   "source": [
    "# Save the data as groundtruth for PARCv2 predictions and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582d9d2f-d812-4106-89cf-7037b5669667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 183139.npy\n",
      "Shape of seq_case before appending: (1, 150, 250, 260)\n",
      "Length of data_whole after appending: 1\n",
      "Processing 183131.npy\n",
      "Shape of seq_case before appending: (1, 150, 250, 260)\n",
      "Length of data_whole after appending: 2\n",
      "Processing 183117.npy\n",
      "Shape of seq_case before appending: (1, 150, 250, 260)\n",
      "Length of data_whole after appending: 3\n",
      "Processing 183138.npy\n",
      "Shape of seq_case before appending: (1, 150, 250, 260)\n",
      "Length of data_whole after appending: 4\n",
      "Processing 183116.npy\n",
      "Shape of seq_case before appending: (1, 150, 250, 260)\n",
      "Length of data_whole after appending: 5\n",
      "Processing 183143.npy\n",
      "Shape of seq_case before appending: (1, 150, 250, 260)\n",
      "Length of data_whole after appending: 6\n",
      "Ground truth saved!\n",
      "(6, 150, 250, 260)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/sfs/qumulo/qhome/jtb3sud/PARCv2\")\n",
    "from PARC.data.data_meta_learning import data_gt\n",
    "seq_clipped = data_gt(sequence_length = 52, n_state_var = 3, folder_path=\"/scratch/jtb3sud/meta_data/tnt/testing\", result_path = \"/scratch/jtb3sud/results/gt\")\n",
    "print(seq_clipped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a06dc-ffc0-4b66-af9b-765b5a90ecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
