{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 17:38:22.414293: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.chdir(\".\")\n",
    "import parc.data.data_em as data\n",
    "#from parc import misc, metrics, visualization\n",
    "from parc.model import model_em as model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get data and normalization\n",
    "state_seq_whole, vel_seq_whole = data.clip_raw_data(idx_range = (0,150))\n",
    "state_seq_norm = data.data_normalization(state_seq_whole,3)\n",
    "vel_seq_norm = data.data_normalization(vel_seq_whole,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Differentiator training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 17:39:23.206071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46594 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Create tf.dataset\n",
    "dataset_input = tf.data.Dataset.from_tensor_slices((state_seq_norm[0][:,:,:,:3],vel_seq_norm[0][:,:,:,:2]))\n",
    "dataset_label = tf.data.Dataset.from_tensor_slices((state_seq_norm[0][:,:,:,-3:],vel_seq_norm[0][:,:,:,-2:]))\n",
    "dataset = tf.data.Dataset.zip((dataset_input, dataset_label))\n",
    "dataset = dataset.shuffle(buffer_size = 2192) \n",
    "dataset = dataset.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "parc = model.PARCv2(n_state_var = 3, n_time_step = 1, step_size= 1/15, solver = \"rk\", mode = \"differentiator_training\")\n",
    "# parc.differentiator.load_weights('parc2_diff_rk4.h5')\n",
    "parc.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001, beta_1 = 0.9, beta_2 = 0.999))\n",
    "parc.fit(dataset, epochs = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parc.differentiator.save_weights('parc2_diff_rk4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Data-driven integration training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pretrain integrator\n",
    "tf.keras.backend.clear_session()\n",
    "parc = model.PARCv2(n_state_var = 3, n_time_step = 1, step_size= 1/15, solver = \"euler\", mode = \"integrator_training\")\n",
    "parc.differentiator.load_weights('./parc2_diff_rk4.h5')\n",
    "parc.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001, beta_1 = 0.9, beta_2 = 0.999))\n",
    "parc.fit(dataset, epochs = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parc.integrator.save_weights('parc2_int_rk4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_seq_whole, vel_seq_whole = data.clip_raw_data(idx_range = (150,200), sequence_length = 15, n_state_var = 3, purpose = \"test\")\n",
    "state_seq_norm_test = data.data_normalization_test(state_seq_whole, state_seq_norm[1], state_seq_norm[2],3)\n",
    "vel_seq_norm_test = data.data_normalization_test(vel_seq_whole, vel_seq_norm[1], vel_seq_norm[2],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "parc_rk = model.PARCv2(n_state_var = 3, n_time_step = 14, step_size= 1/15, solver = \"rk4\")\n",
    "parc_rk.compile()\n",
    "parc_rk.differentiator.load_weights('parc2_diff_rk4.h5')\n",
    "parc_rk.integrator.load_weights('parc2_int_rk4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rk = []\n",
    "outlier = [0, 3, 30, 31, 32, 33, 18, 19, 11]\n",
    "# outlier = []\n",
    "for idx in range(34):\n",
    "    if idx not in outlier:\n",
    "        print(idx)\n",
    "        state_var_current = state_seq_norm_test[idx:idx+1,:,:,0:3]\n",
    "        velocity_current = vel_seq_norm_test[idx:idx+1,:,:,0:2]\n",
    "        pred_state = parc_rk.predict([state_var_current,velocity_current])\n",
    "        pred_state_case = np.concatenate(pred_state, axis = -1)\n",
    "        print(pred_state_case.shape)\n",
    "        state_rk.append(pred_state_case)\n",
    "state_rk = np.concatenate(state_rk, axis = 0)\n",
    "print(state_rk.shape)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_out = data.clip_raw_datadata_denormalization(pred,min_val_state,max_val_state, no_of_channel = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('./plotting/em/parcv2_em.npy',pred_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rk = []\n",
    "outlier = [0, 3, 30, 31, 32, 33, 18, 19, 11]\n",
    "# outlier = []\n",
    "for idx in range(34):\n",
    "    if idx not in outlier:\n",
    "        print(idx)\n",
    "        state_var_current = state_seq_norm_test[idx:idx+1,:,:,0:3]\n",
    "        velocity_current = vel_seq_norm_test[idx:idx+1,:,:,0:2]\n",
    "        pred_state = parc_rk.predict([state_var_current,velocity_current])\n",
    "        pred_state_case = np.concatenate(pred_state, axis = -1)\n",
    "        print(pred_state_case.shape)\n",
    "        state_rk.append(pred_state_case)\n",
    "state_rk = np.concatenate(state_rk, axis = 0)\n",
    "print(state_rk.shape)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity(y_true, y_pred_euler, y_pred_rk, metric, ts):\n",
    "    \"\"\"sensitivity plot comparing true and prediction\n",
    "    :param y_true:  (tuple)\n",
    "    :param y_pred:  (tuple)\n",
    "    :param metric:  (str)   metric for plotting. {hs_temp, hs_area, rate_hs_temp, rate_hs_area}\n",
    "    \"\"\"\n",
    "\n",
    "    if metric == \"hs_temp\" or metric == \"hs_area\":\n",
    "        ts = np.linspace(3.16, 15.01, ts)\n",
    "    elif metric == \"rate_hs_temp\" or metric == \"rate_hs_area\":\n",
    "        ts = np.linspace(3.16, 14.22, ts - 1)\n",
    "    else:\n",
    "        print(\n",
    "            \"Wrong metric selection. Possible metrics are: 'hs_temp', 'hs_area', 'rate_hs_temp', 'rate_hs_area\"\n",
    "        )\n",
    "\n",
    "    col_true, col_pred, col_yel = \"#277DA1\", \"#F94144\", \"#F9C74F\"\n",
    "    plt.figure(figsize=(13, 10))\n",
    "\n",
    "    # mean values\n",
    "    plt.plot(ts, y_true[0], color=col_true, lw=2.5, label=\"Ground truth\")\n",
    "    plt.plot(ts, y_pred_rk[0], color=col_pred, lw=2.5, label=\"PARC-RK4\")\n",
    "#     plt.plot(ts, y_pred_euler[0], color=col_yel, lw=2.5, label=\"PARC-Euler\")\n",
    "\n",
    "    # plot intervals\n",
    "    plt.fill_between(ts, y_true[1], y_true[2], color=col_true, alpha=0.2)\n",
    "    plt.fill_between(ts, y_pred_rk[1], y_pred_rk[2], color=col_pred, alpha=0.2)\n",
    "#     plt.fill_between(ts, y_pred_euler[1], y_pred_euler[2], color=col_yel, alpha=0.2)\n",
    "\n",
    "    # corresponding titles and wordings based on the metric\n",
    "    if metric == \"hs_temp\":\n",
    "        plt.title(r\"Ave. Hotspot Temperature ($T_{hs}$)\", fontsize=32, pad=15)\n",
    "        plt.xlabel(r\"t ($ns$)\", fontsize=28)\n",
    "        plt.ylabel(r\" $T_{hs}$ ($K$)\", fontsize=28)\n",
    "        plt.axis([3.16, 15.01, 0, 5000])\n",
    "    elif metric == \"hs_area\":\n",
    "        plt.title(r\"Hotspot Area ($A_{hs}$)\", fontsize=32, pad=15)\n",
    "        plt.xlabel(r\"t ($ns$)\", fontsize=28)\n",
    "        plt.ylabel(r\"$A_{hs}$ \", fontsize=28)\n",
    "        plt.axis([3.16, 15.01, 0, 25])\n",
    "    elif metric == \"rate_hs_temp\":\n",
    "        plt.title(\n",
    "            r\"Ave. Hotspot Temperature Rate of Change ($\\dot{T_{hs}}$)\",\n",
    "            fontsize=32,\n",
    "            pad=15,\n",
    "        )\n",
    "        plt.xlabel(r\"t ($ns$)\", fontsize=28)\n",
    "        plt.ylabel(r\"$\\dot{T_{hs}}$ ($K$/$ns$)\", fontsize=28)\n",
    "        plt.axis([3.16, 15.01, -30, 1200])\n",
    "    else:\n",
    "        plt.title(r\"Hotspot Area Rate of Change ($\\dot{A_{hs}}$)\", fontsize=32, pad=15)\n",
    "        plt.xlabel(r\"t ($ns$)\", fontsize=28)\n",
    "        plt.ylabel(r\"$\\dot{A_{hs}}$\", fontsize=28)\n",
    "        plt.axis([3.16, 15.01, 0, 10])\n",
    "\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.legend(loc=2, fontsize=28)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess temperature data\n",
    "# Get temperature field evolution\n",
    "# Temp_gt = np.delete(state_seq_norm_test, outlier, 0)\n",
    "# Temp_gt = Temp_gt[:,:,:,3::3]    # Ground truth temperature field evolution\n",
    "Temp_gt = state_seq_norm_test[:,:,:,3::3]    # Ground truth temperature field evolution\n",
    "# Temp_gt = np.clip(Temp_gt,0,1)\n",
    "Temp_pred_parc_rk = state_rk[:,:,:,0::5]   # PARC prediction temperature field evolution\n",
    "Temp_pred_parc_euler = state_euler[:,:,:,0::5]   # PARC prediction temperature field evolution\n",
    "\n",
    "# # Denormalize temperature field evolution\n",
    "Temp_gt = misc.scale_temperature(temperatures = Temp_gt, start_ts = 0, max_temp = 5000, min_temp = 300)\n",
    "Temp_pred_parc_rk = misc.scale_temperature(temperatures = Temp_pred_parc_rk, start_ts = 0, max_temp = 5000, min_temp = 300)\n",
    "Temp_pred_parc_euler = misc.scale_temperature(temperatures = Temp_pred_parc_euler, start_ts = 0, max_temp = 5000, min_temp = 300)\n",
    "\n",
    "# Compute sensitivity of ground truth data\n",
    "gt_hs_temp, gt_hs_area = metrics.calculate_hotspot_metric(Temp_gt[:,:,:,0:], cases_range = (0,25), n_timesteps = 15)\n",
    "gt_rate_hs_temp,gt_rate_hs_area = metrics.calculate_hotspot_metric_rate_of_change(Temp_gt[:,:,:,0:], cases_range = (0,25), n_timesteps = 15)\n",
    "\n",
    "# Compute sensitivity of PARC prediction\n",
    "parc_hs_temp_rk, parc_hs_area_rk = metrics.calculate_hotspot_metric(Temp_pred_parc_rk[:,:,:,0:], cases_range = (0,25), n_timesteps =15)\n",
    "parc_rate_hs_temp_rk, parc_rate_hs_area_rk = metrics.calculate_hotspot_metric_rate_of_change(Temp_pred_parc_rk[:,:,:,0:], cases_range = (0,25), n_timesteps = 15)\n",
    "\n",
    "# Compute sensitivity of PARC prediction\n",
    "parc_hs_temp_euler, parc_hs_area_euler = metrics.calculate_hotspot_metric(Temp_pred_parc_euler[:,:,:,0:], cases_range = (0,25), n_timesteps =15)\n",
    "parc_rate_hs_temp_euler, parc_rate_hs_area_euler = metrics.calculate_hotspot_metric_rate_of_change(Temp_pred_parc_euler[:,:,:,0:], cases_range = (0,25), n_timesteps = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivity(y_true=gt_hs_temp, y_pred_rk=parc_hs_temp_rk, y_pred_euler = parc_hs_temp_euler,  metric='hs_temp',ts=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivity(y_true=gt_hs_area, y_pred_rk=parc_hs_area_rk, y_pred_euler = parc_hs_area_euler, metric='hs_area',ts=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivity(y_true=gt_rate_hs_temp, y_pred_rk=parc_rate_hs_temp_rk, y_pred_euler = parc_rate_hs_temp_euler, metric='rate_hs_temp',ts=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivity(y_true=gt_rate_hs_area, y_pred_rk=parc_rate_hs_area_rk, y_pred_euler = parc_rate_hs_area_euler, metric='rate_hs_area',ts=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess temperature data\n",
    "# Get temperature field evolution\n",
    "# Temp_gt = np.delete(state_seq_norm_test, outlier, 0)\n",
    "# Temp_gt = Temp_gt[:,:,:,3::3]    # Ground truth temperature field evolution\n",
    "P_gt = vel_seq_norm_test[:,:,:,4::3]    # Ground truth temperature field evolution\n",
    "# Temp_gt = np.clip(Temp_gt,0,1)\n",
    "P_pred_parc_rk = state_rk[:,:,:,1::5]   # PARC prediction temperature field evolution\n",
    "\n",
    "# # Denormalize temperature field evolution\n",
    "Temp_gt = misc.scale_temperature(temperatures = Temp_gt, start_ts = 0, max_temp = 50e9, min_temp = -2e9)\n",
    "Temp_pred_parc_rk = misc.scale_temperature(temperatures = Temp_pred_parc_rk, start_ts = 0, max_temp = 50e9, min_temp = -2e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivity(y_true=gt_rate_hs_area, y_pred_rk=parc_rate_hs_area_rk, y_pred_euler = parc_rate_hs_area_euler, metric='rate_hs_area',ts=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
